{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQtNUwPBG8b7KqCg7A/el9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaesu96/gaesu_public/blob/main/%08opencv_detection_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uLpwZUqlCyJf"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def get_detected_img(cv_net, img_array, score_threshold, is_print=True):\n",
        "\n",
        "    rows = img_array.shape[0]\n",
        "    cols = img_array.shape[1]\n",
        "\n",
        "    draw_img = img_array.copy()\n",
        "\n",
        "    cv_net.setInput(cv2.dnn.blobFromImage(img_array, size=(300, 300), swapRB=True, crop=False))\n",
        "\n",
        "    start = time.time()\n",
        "    cv_out = cv_net.forward()\n",
        "\n",
        "    green_color=(0, 255, 0)\n",
        "    red_color=(0, 0, 255)\n",
        "\n",
        "    # detected 된 object들을 iteration 하면서 정보 추출\n",
        "    for detection in cv_out[0,0,:,:]:\n",
        "        score = float(detection[2])\n",
        "        class_id = int(detection[1])\n",
        "        # detected된 object들의 score가 0.4 이상만 추출\n",
        "        if score > score_threshold:\n",
        "            # detected된 object들은 image 크기가 (300, 300)으로 scale된 기준으로 예측되었으므로 다시 원본 이미지 비율로 계산\n",
        "            left = detection[3] * cols\n",
        "            top = detection[4] * rows\n",
        "            right = detection[5] * cols\n",
        "            bottom = detection[6] * rows\n",
        "            # labels_to_names 딕셔너리로 class_id값을 클래스명으로 변경. opencv에서는 class_id + 1로 매핑해야함.\n",
        "            caption = \"{}: {:.4f}\".format(labels_to_names[class_id], score)\n",
        "\n",
        "            #cv2.rectangle()은 인자로 들어온 draw_img에 사각형을 그림. 위치 인자는 반드시 정수형.\n",
        "            cv2.rectangle(draw_img, (int(left), int(top)), (int(right), int(bottom)), color=green_color, thickness=2)\n",
        "            cv2.putText(draw_img, caption, (int(left), int(top - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, red_color, 2)\n",
        "    if is_print:\n",
        "        print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n",
        "\n",
        "    return draw_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def do_detected_video(cv_net, input_path, output_path, score_threshold, is_print):\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n",
        "\n",
        "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print('총 Frame 갯수:', frame_cnt, )\n",
        "\n",
        "    green_color=(0, 255, 0)\n",
        "    red_color=(0, 0, 255)\n",
        "    while True:\n",
        "        hasFrame, img_frame = cap.read()\n",
        "        if not hasFrame:\n",
        "            print('더 이상 처리할 frame이 없습니다.')\n",
        "            break\n",
        "\n",
        "        returned_frame = get_detected_img(cv_net, img_frame, score_threshold=score_threshold, is_print=True)\n",
        "        vid_writer.write(returned_frame)\n",
        "    # end of while loop\n",
        "\n",
        "    vid_writer.release()\n",
        "    cap.release()"
      ],
      "metadata": {
        "id": "7i_OVrjIDBTu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mobilenet-SSD-V3만 해당"
      ],
      "metadata": {
        "id": "Y417bkAgE4Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def get_detected_img_renew(cv_net, img_array, score_threshold, is_print=True):\n",
        "\n",
        "  draw_img = img_array.copy()\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  classes, confidences, boxes = cv_net.detect(img_array, confThreshold=0.5)\n",
        "\n",
        "  green_color=(0, 255, 0)\n",
        "  red_color=(0, 0, 255)\n",
        "\n",
        "  # detected 된 object들을 iteration 하면서 정보 추출\n",
        "  for class_id, confidence_score, box in zip(classes.flatten(), confidences.flatten(), boxes):\n",
        "    if confidence_score > 0.5:\n",
        "      caption = \"{}: {:.4f}\".format(labels_to_names[class_id], confidence_score)\n",
        "      cv2.rectangle(draw_img, (box[0], box[1]), (box[0]+box[2], box[1]+box[3]), color=green_color, thickness=2)\n",
        "      cv2.putText(draw_img, caption, (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.6, red_color, 2)\n",
        "      print(caption)\n",
        "\n",
        "  if is_print:\n",
        "      print('Detection 수행시간:',round(time.time() - start, 2),\"초\")\n",
        "\n",
        "  return draw_img"
      ],
      "metadata": {
        "id": "In691gc1DENG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cv_detection_model(pretrained_path, config_path):\n",
        "  cv_net = cv2.dnn_DetectionModel(pretrained_path, config_path)\n",
        "  cv_net.setInputSize(320, 320)\n",
        "  cv_net.setInputScale(1.0 / 127.5)\n",
        "  cv_net.setInputMean((127.5, 127.5, 127.5))\n",
        "  cv_net.setInputSwapRB(True)\n",
        "\n",
        "  return cv_net"
      ],
      "metadata": {
        "id": "KD7cac_oDIBk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_detected_video_renew(cv_net, input_path, output_path, score_threshold, is_print):\n",
        "\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "    vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    vid_writer = cv2.VideoWriter(output_path, codec, vid_fps, vid_size)\n",
        "\n",
        "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print('총 Frame 갯수:', frame_cnt, )\n",
        "\n",
        "    green_color=(0, 255, 0)\n",
        "    red_color=(0, 0, 255)\n",
        "    while True:\n",
        "        hasFrame, img_frame = cap.read()\n",
        "        if not hasFrame:\n",
        "            print('더 이상 처리할 frame이 없습니다.')\n",
        "            break\n",
        "\n",
        "        returned_frame = get_detected_img_renew(cv_net, img_frame, score_threshold=score_threshold, is_print=True)\n",
        "        vid_writer.write(returned_frame)\n",
        "    # end of while loop\n",
        "\n",
        "    vid_writer.release()\n",
        "    cap.release()"
      ],
      "metadata": {
        "id": "6PEIfq4jDLH4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SIcHBVAnDNUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}